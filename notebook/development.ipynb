{"cells":[{"source":"![](./cover.jpg)\n\nYour airline's customer service team has been collecting chat data for years—thousands of conversations, each labeled with the user’s intent and an ideal response. Now, it's time to put that data to work.\n\nYou've been tasked with fine-tuning a TinyLlama model to power the airline’s next-gen AI assistant. The goal? Given a user message, the model should predict the intent (like booking a flight, checking baggage status, or requesting special assistance) and generate a helpful, human-like response. Accurate intent detection is key since it helps the system understand what the customer wants, so it can respond appropriately and trigger downstream actions when needed.\n\n### The Data\nYou'll work with a dataset of various travel query examples. \n\n Column | Description |\n|--------|-------------|\n| ```instruction``` | A user request from the Travel domain |\n| ```category``` | The high-level semantic category for the intent |\n| ```intent``` | The specific intent corresponding to the user instruction |\n| ```response``` | An example of an expected response from the virtual assistant |\n\n___\n### Update to Python 3.10\n\nDue to how frequently the libraries required for this project are updated, you'll need to update your environment to Python 3.10:\n\n1. In the workbook, click on \"Environment,\" in the top toolbar and select \"Session details\".\n\n2. In the workbook language dropdown, select \"Python 3.10\".\n\n3. Click \"Confirm\" and hit \"Done\" once the session is ready.","metadata":{},"id":"40386fc5-3663-4cca-a90b-4a414e75a229","cell_type":"markdown"},{"source":"# First install the necessary packages\n!pip install -q -q -q trl==0.16.0\n!pip install -q -q -q tf-keras==2.19.0\n!pip install -q -q -q peft","metadata":{"executionCancelledAt":null,"executionTime":9461,"lastExecutedAt":1761855399429,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# First install the necessary packages\n!pip install -q -q -q trl==0.16.0\n!pip install -q -q -q tf-keras==2.19.0\n!pip install -q -q -q peft","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"id":"de19a3c2-640a-4783-8cde-5a95e88d9bc2","cell_type":"code","execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"}]},{"source":"# Import the required dependencies for this project\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig\n\nfrom datasets import Dataset, load_dataset\nfrom collections import Counter, defaultdict\nimport random","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1761855399480,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the required dependencies for this project\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig\n\nfrom datasets import Dataset, load_dataset\nfrom collections import Counter, defaultdict\nimport random","outputsMetadata":{"0":{"height":416,"type":"stream"}}},"id":"14082b66-5845-496b-888a-ebf28e4927a6","cell_type":"code","execution_count":56,"outputs":[]},{"source":"The code below loads the travel query dataset and reduces it from ~30k to ~50 records, keeping all intent types. This speeds up fine-tuning. Run it before starting, and feel free to experiment with it later!","metadata":{},"id":"d295fc56-0302-41a3-a1be-a863547fdef4","cell_type":"markdown"},{"source":"# First load the entire dataset\nds = load_dataset('bitext/Bitext-travel-llm-chatbot-training-dataset', split=\"train\")\n\n# Group examples by intent\nrandom.seed(42)\nintent_groups = defaultdict(list)\nfor record in ds:\n    intent = record[\"intent\"]\n    intent_groups[intent].append(record)\n\n# Determine how many samples per intent\ntotal_intents = len(intent_groups)\nsamples_per_intent = 100 // total_intents\n\n# Sample from each intent\nbalanced_subset = []\nfor intent, examples in intent_groups.items():\n    sampled = random.sample(examples, min(samples_per_intent, len(examples)))\n    balanced_subset.extend(sampled)\n\ntotal_num_of_records = 50    \ntravel_chat_ds = Dataset.from_list(balanced_subset[:total_num_of_records])\n\ntravel_chat_ds.to_pandas().head(3)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":210,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"f62c2997-7fde-4538-b6f9-ff8797ebb5ba","nodeType":"const"}}},"1":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"7da20b7d-655a-4080-87b0-f429ec0cf6a0","nodeType":"const"},"quickFilterText":""}},"3":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"a692c49b-e7eb-412e-9663-6ba34b6df170","nodeType":"const"}}},"4":{"height":50,"type":"dataFrame","tableState":{"quickFilterText":"","customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"7da20b7d-655a-4080-87b0-f429ec0cf6a0","nodeType":"const"}}}}},"id":"daa57ab5-d87c-42e6-808e-1e048ae3e0ad","cell_type":"code","execution_count":57,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"instruction","type":"string"},{"name":"intent","type":"string"},{"name":"category","type":"string"},{"name":"tags","type":"string"},{"name":"response","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2],"instruction":["I'd like information about my checked baggage allowance, how can I find it?","i have to see the fucking checked baggage allowance can i get some help","I want to know about my checked baggage allowance, where can I find more information?"],"intent":["check_baggage_allowance","check_baggage_allowance","check_baggage_allowance"],"category":["BAGGAGE","BAGGAGE","BAGGAGE"],"tags":["BCIP","BCIQW","BCI"],"response":["To retrieve your checked baggage allowance details, please follow these instructions:\n\n1. Visit {{WEBSITE_URL}} or launch the {{APP_NAME}} application.\n2. Log in to your personal account.\n3. Select the {{BOOKINGS_OPTION}} section.\n4. Enter the required booking or flight information.\n5. The specific baggage allowance for your trip will be displayed.\n\nShould you require additional help, do not hesitate to contact customer support via the {{APP_NAME}} app or on {{WEBSITE_URL}}.","To determine your checked baggage allowance, please follow these instructions: \n\n1. Go to {{WEBSITE_URL}} or launch the {{APP_NAME}} app. \n2. Log in to your account. \n3. Select the {{BOOKINGS_OPTION}} section. \n4. Enter the relevant booking or flight details. \n5. You will then see your checked baggage allowance information. \n\nIf you need further help, contact our customer service via the {{APP_NAME}} app or visit {{WEBSITE_URL}} for more support.","To find details regarding your checked baggage allowance, please follow these steps:\n\n1. Visit {{WEBSITE_URL}} or access the {{APP_NAME}} application.\n2. Log into your personal account.\n3. Select the {{BOOKINGS_OPTION}} section.\n4. Enter your booking reference or flight information.\n5. Your baggage allowance will be displayed accordingly.\n\nFor additional help, reach out to our customer support team available via the {{APP_NAME}} app or on {{WEBSITE_URL}}."]}},"total_rows":3,"truncation_type":null},"text/plain":"                                         instruction  ...                                           response\n0  I'd like information about my checked baggage ...  ...  To retrieve your checked baggage allowance det...\n1  i have to see the fucking checked baggage allo...  ...  To determine your checked baggage allowance, p...\n2  I want to know about my checked baggage allowa...  ...  To find details regarding your checked baggage...\n\n[3 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>intent</th>\n      <th>category</th>\n      <th>tags</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'd like information about my checked baggage ...</td>\n      <td>check_baggage_allowance</td>\n      <td>BAGGAGE</td>\n      <td>BCIP</td>\n      <td>To retrieve your checked baggage allowance det...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i have to see the fucking checked baggage allo...</td>\n      <td>check_baggage_allowance</td>\n      <td>BAGGAGE</td>\n      <td>BCIQW</td>\n      <td>To determine your checked baggage allowance, p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I want to know about my checked baggage allowa...</td>\n      <td>check_baggage_allowance</td>\n      <td>BAGGAGE</td>\n      <td>BCI</td>\n      <td>To find details regarding your checked baggage...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":57}]},{"source":"# Start the project with the dataset below\n\nprint(travel_chat_ds)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1761855401474,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start the project with the dataset below\n\nprint(travel_chat_ds)","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"id":"7daaca1d-0c39-4ed5-8631-a61c30f00f36","cell_type":"code","execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":"Dataset({\n    features: ['instruction', 'intent', 'category', 'tags', 'response'],\n    num_rows: 50\n})\n"}]},{"source":"print(travel_chat_ds[0])","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1761855401525,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(travel_chat_ds[0])","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"7a223e97-00fd-489e-bc12-76239fc3f9d2","outputs":[{"output_type":"stream","name":"stdout","text":"{'instruction': \"I'd like information about my checked baggage allowance, how can I find it?\", 'intent': 'check_baggage_allowance', 'category': 'BAGGAGE', 'tags': 'BCIP', 'response': 'To retrieve your checked baggage allowance details, please follow these instructions:\\n\\n1. Visit {{WEBSITE_URL}} or launch the {{APP_NAME}} application.\\n2. Log in to your personal account.\\n3. Select the {{BOOKINGS_OPTION}} section.\\n4. Enter the required booking or flight information.\\n5. The specific baggage allowance for your trip will be displayed.\\n\\nShould you require additional help, do not hesitate to contact customer support via the {{APP_NAME}} app or on {{WEBSITE_URL}}.'}\n"}],"execution_count":59},{"source":"# Start coding here\n# Use as many cells as you need\ndef merger_conversation(row):\n    row['conversation'] = f\"Query: {row['instruction']}\\nResponse: {row['response']}\"\n    return row\n\t\ntravel_chat_ds_ = travel_chat_ds.map(merger_conversation)\n\nprint(travel_chat_ds_[0]['conversation'])","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1761855401585,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here\n# Use as many cells as you need\ndef merger_conversation(row):\n    row['conversation'] = f\"Query: {row['instruction']}\\nResponse: {row['response']}\"\n    return row\n\t\ntravel_chat_ds_ = travel_chat_ds.map(merger_conversation)\n\nprint(travel_chat_ds_[0]['conversation'])","outputsMetadata":{"1":{"height":248,"type":"stream"}}},"id":"07446785-915c-472d-971e-132f08ab9371","cell_type":"code","execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4d24e5010204681bee1ade0c4388a5a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"Query: I'd like information about my checked baggage allowance, how can I find it?\nResponse: To retrieve your checked baggage allowance details, please follow these instructions:\n\n1. Visit {{WEBSITE_URL}} or launch the {{APP_NAME}} application.\n2. Log in to your personal account.\n3. Select the {{BOOKINGS_OPTION}} section.\n4. Enter the required booking or flight information.\n5. The specific baggage allowance for your trip will be displayed.\n\nShould you require additional help, do not hesitate to contact customer support via the {{APP_NAME}} app or on {{WEBSITE_URL}}.\n"}]},{"source":"travel_chat_ds_.save_to_disk(\"preprocessed_dataset\")","metadata":{"executionCancelledAt":null,"executionTime":99,"lastExecutedAt":1761855401684,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"travel_chat_ds_.save_to_disk(\"preprocessed_dataset\")"},"cell_type":"code","id":"766f4f85-54da-4c81-aed3-e0072bb1be82","outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d80e5f91893b4012aaaebebbe2fe071e"}},"metadata":{}}],"execution_count":61},{"source":"model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v0.1\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"executionCancelledAt":null,"executionTime":353,"lastExecutedAt":1761855402038,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v0.1\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token"},"cell_type":"code","id":"01b03b5f-1655-42cd-8a70-740ec06a51a0","outputs":[],"execution_count":62},{"source":"lora_config = LoraConfig(\n  \tr=12,\n    lora_alpha=8,\n  \ttask_type=\"CAUSAL_LM\",\n    lora_dropout=0.05,\n    bias=\"none\",\n    target_modules=['q_proj', 'v_proj']\n)","metadata":{"executionCancelledAt":null,"executionTime":45,"lastExecutedAt":1761855402084,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"lora_config = LoraConfig(\n  \tr=12,\n    lora_alpha=8,\n  \ttask_type=\"CAUSAL_LM\",\n    lora_dropout=0.05,\n    bias=\"none\",\n    target_modules=['q_proj', 'v_proj']\n)"},"cell_type":"code","id":"50f59f5c-e408-49b5-a30e-d58f09504d19","outputs":[],"execution_count":63},{"source":"from trl import SFTConfig \nfrom transformers import TrainingArguments\n\n# Los argumentos de entrenamiento (TrainingArguments) van directamente al SFTConfig\nsft_config = SFTConfig(\n    \n    # Parámetros de TrainingArguments:\n    learning_rate=2e-3, \n    warmup_ratio=0.03,\n    num_train_epochs=3,\n    output_dir='/tmp',\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=1,\n    save_steps=10,\n    logging_steps=2,\n    lr_scheduler_type='constant',\n    report_to='none',\n    \n    dataset_text_field='conversation', \n    max_seq_length=250,\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=travel_chat_ds_,\n    args=sft_config, \n    peft_config=lora_config,\n    # tokenizer=tokenizer\n)\n\ntrainer.train()","metadata":{"executionCancelledAt":null,"executionTime":243038,"lastExecutedAt":1761855645124,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from trl import SFTConfig \nfrom transformers import TrainingArguments\n\n# Los argumentos de entrenamiento (TrainingArguments) van directamente al SFTConfig\nsft_config = SFTConfig(\n    \n    # Parámetros de TrainingArguments:\n    learning_rate=2e-3, \n    warmup_ratio=0.03,\n    num_train_epochs=3,\n    output_dir='/tmp',\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=1,\n    save_steps=10,\n    logging_steps=2,\n    lr_scheduler_type='constant',\n    report_to='none',\n    \n    dataset_text_field='conversation', \n    max_seq_length=250,\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=travel_chat_ds_,\n    args=sft_config, \n    peft_config=lora_config,\n    # tokenizer=tokenizer\n)\n\ntrainer.train()"},"cell_type":"code","id":"dd9cd306-e17d-4424-923a-715fcf244e7f","outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56c947b5e214d54943d905fe9750b64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c73452bec584931be376b1771be25df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74912ab59c4b4a8994d88ea581e91627"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff949802f8140dcab4097737400bc71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/150 : < :, Epoch 0.02/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=150, training_loss=0.90884179631869, metrics={'train_runtime': 241.9248, 'train_samples_per_second': 0.62, 'train_steps_per_second': 0.62, 'total_flos': 155424387575808.0, 'train_loss': 0.90884179631869})"},"metadata":{},"execution_count":64}],"execution_count":64},{"source":"trainer.model.save_pretrained(\"./tinyllama_travel_adapter\")","metadata":{"executionCancelledAt":null,"executionTime":523,"lastExecutedAt":1761855645647,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"trainer.model.save_pretrained(\"./tinyllama_travel_adapter\")"},"cell_type":"code","id":"1945761d-2f9d-4584-a15a-bbd1d68c88dd","outputs":[],"execution_count":65},{"source":"tokenizer.save_pretrained(\"./tinyllama_travel_adapter\")","metadata":{"executionCancelledAt":null,"executionTime":240,"lastExecutedAt":1761855645888,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"tokenizer.save_pretrained(\"./tinyllama_travel_adapter\")"},"cell_type":"code","id":"0c02f45e-5acb-4720-b4e1-440414971063","outputs":[{"output_type":"execute_result","data":{"text/plain":"('./tinyllama_travel_adapter/tokenizer_config.json',\n './tinyllama_travel_adapter/special_tokens_map.json',\n './tinyllama_travel_adapter/tokenizer.model',\n './tinyllama_travel_adapter/added_tokens.json',\n './tinyllama_travel_adapter/tokenizer.json')"},"metadata":{},"execution_count":66}],"execution_count":66},{"source":"from peft import LoraConfig, PeftModel\nimport torch\n\noutput_dir = \"./tinyllama_travel_adapter\"\n\nbase_model_for_inference = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nmodel_with_peft = PeftModel.from_pretrained(\n    base_model_for_inference, \n    output_dir\n)\n\nmerged_model = model_with_peft.merge_and_unload()\nmerged_model.eval()\nprint(\"Modelo base y adaptadores LoRA fusionados para inferencia.\")","metadata":{"executionCancelledAt":null,"executionTime":1482,"lastExecutedAt":1761855647370,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from peft import LoraConfig, PeftModel\nimport torch\n\noutput_dir = \"./tinyllama_travel_adapter\"\n\nbase_model_for_inference = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nmodel_with_peft = PeftModel.from_pretrained(\n    base_model_for_inference, \n    output_dir\n)\n\nmerged_model = model_with_peft.merge_and_unload()\nmerged_model.eval()\nprint(\"Modelo base y adaptadores LoRA fusionados para inferencia.\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"bc98d156-b581-40a5-8cfe-e71e079e783d","outputs":[{"output_type":"stream","name":"stdout","text":"Modelo base y adaptadores LoRA fusionados para inferencia.\n"}],"execution_count":67},{"source":"def generate_travel_response(instruction, merged_model, tokenizer):\n    prompt = f\"Query: {instruction}\\nResponse:\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n    device = merged_model.device\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        output_tokens = merged_model.generate(\n        **inputs, \n        max_new_tokens=100, \n        do_sample=True,\n        temperature=0.7,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    full_response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n\n    try:\n        model_response = full_response.split(\"Response:\")[1].strip()\n    except IndexError:\n        model_response = \"Error al decodificar o el modelo no generó el separador esperado.\"\n\n    return model_response","metadata":{"executionCancelledAt":null,"executionTime":24,"lastExecutedAt":1761855647394,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def generate_travel_response(instruction, merged_model, tokenizer):\n    prompt = f\"Query: {instruction}\\nResponse:\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n    device = merged_model.device\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        output_tokens = merged_model.generate(\n        **inputs, \n        max_new_tokens=100, \n        do_sample=True,\n        temperature=0.7,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    full_response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n\n    try:\n        model_response = full_response.split(\"Response:\")[1].strip()\n    except IndexError:\n        model_response = \"Error al decodificar o el modelo no generó el separador esperado.\"\n\n    return model_response"},"cell_type":"code","id":"57b4988a-5a0b-4a5a-84b8-d3a53056ff1c","outputs":[],"execution_count":68},{"source":"instruction_to_test = \"I'd like information about my checked baggage allowance, how can I find it?\"\nmodel_response = generate_travel_response(instruction_to_test, merged_model, tokenizer)","metadata":{"executionCancelledAt":null,"executionTime":66049,"lastExecutedAt":1761855713444,"lastExecutedByKernel":"17a35664-6688-41eb-a90a-7ee2b74df254","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"instruction_to_test = \"I'd like information about my checked baggage allowance, how can I find it?\"\nmodel_response = generate_travel_response(instruction_to_test, merged_model, tokenizer)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"2f505c1b-b1ad-4a00-838d-b8762e015147","outputs":[{"output_type":"stream","name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"}],"execution_count":69},{"source":"print(model_response)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"90d1cb5c-bd2f-4b7e-a6a9-b57c7f9e06e3","outputs":[{"output_type":"stream","name":"stdout","text":"To retrieve your checked baggage allowance details, please follow these steps:\n\n1. Visit {{WEBSITE_URL}} or launch a {{APP_NAME}} app.\n2. Log in to your personal account.\n3. Select the {{BOOKINGS_OPTION}} tab.\n4. Enter or search for your booking reference number.\n\nShould you require more assistance, our {{CUSTOMER_SUPPORT}} team is ready\n"}],"execution_count":70}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}