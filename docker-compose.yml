services:
  llm-assistant:
    build:
      context: .
      dockerfile: Dockerfile
    
    volumes:
      - .:/app
    
    # 3. Define el comando de ejecución
    # Ejecuta el pipeline principal de Python
    # command: python src/main.py
    
    # 4. Asigna más memoria/CPU si es necesario
    # resources:
    #   limits:
    #     memory: 8G 
    #     cpus: '4'

    # 5. Mantiene el contenedor activo para inspección
    entrypoint: ["/bin/bash"] 
    tty: true